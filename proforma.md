## approach
- RL
  - Monte Carlo Policy Gradients: 
  - actor critic: someone making a move, and there is a "critique"(i.e. evaluator)
    - e.g. A3C (Async advantage actor critic). A2C (without async)
- Minimax

## why?


## how?
### Splitting the work


## Notes: what are we supposed write on this?



## Resources
Pytorch tutorial - https://torlenor.org/machine%20learning/reinforcement%20learning/2020/10/23/machine_learning_reinforment_learning_kalah_part1.html


